# What the Dialogue Path Confronts

**AXhrk the Seeker**
December 15, 2025

---

## Introduction

We are now standing at a major turning point in human history.

Human history—shaped by hunting and gathering, agriculture, industrialization, and informatization—is entering a new phase: the age of AI. Yet this transition is not merely a technological innovation. It is an existential crisis that calls into question the very meaning of human existence.

The historian Yuval Noah Harari warned in *Homo Deus* that the advent of the AI age would produce a “useless class.” This does not mean simply the unemployed. It refers to people who are structurally unemployable—those abandoned by society. In Harari’s words, “The useless class is not just unemployed; it is unemployable.”

What is the essence of this crisis? It is not merely the loss of jobs. It is the loss of the very grounds on which humans possess value as humans. This paper analyzes the structure of this profound problem as **“structural nihilism called Dataism,”** and sketches the infernal future that awaits beyond it.

What would such a world look like?

Just before everything comes to an end, the final cries of the remaining souls may echo as two voices—

---

### One Voice (A Person Who Has Lost All Relationships)

I no longer speak with anyone.
I wake up in the morning, and my device tells me “today’s optimal schedule.”
I only see my family’s faces through a screen.
My child’s voice is replaced by AI-generated sound.

“Dad, I love you.”
That is a perfect simulation, based on past data.
The real warmth is gone.

When I walk through the city, no one meets my eyes.
Our gazes merely scan one another as potential threats.
Friends were quietly removed from the list after an algorithm deemed them “inefficient.”
The person I loved was “reallocated” far away for “resource consumption optimization.”

I am useless.
My job was taken by AI; even my consumption is a burden on the system.
My existence is nothing but a liability.

“I’m sorry I was born”—
I cannot even say those words.
Because no one is listening.

I wanted to be angry.
I wanted to scream.
I wanted solidarity.

But the algorithm classifies my emotions as “irrational” and calmly recommends a sedative.
Each day, my reasons to resist grow thinner.
The story of hope has been deleted.
The future is already predicted.

I am just a data point.
Where did my soul go?

Someone—
please listen to my voice.
I am here…
And yet no one sees me.

---

### Another Voice (A Person Excluded as “Useless”)

“There are no resources to feed you.”

On the day I was told that,
I was still alive.

The factory closed.
The fields were taken over by AI drones.
My hands are no longer worth anything.

My children were separated from me by a nutrition-optimization program,
taken away from an “inefficient parent.”
My wife was transferred to another “useful unit” under “resource redistribution.”

I am in a detention zone on the outskirts of the city.
Food is calculated to the minimum.
Water is monitored.

Every morning, the device tells me:
“Your existence is a burden on the planet.”

Anger surged.
I clenched my fists.
But I don’t know where to direct it.

The enemy has no face.
It is the algorithm.
The system.
No one takes responsibility.

At night, I whisper to myself:
“I only lived. I loved. I laughed. I cried. Was that a crime?”

But my voice is swallowed by the walls.
Those who resisted were quietly erased “for optimization.”

In the end, I think:
“What did it mean to be human?”

If there are no resources, then kill them—
A day will come when such logic is taken for granted.
Perhaps I am waiting for that day.

Someone, tell me.
Where was the value of living?

---

These two cries are not from a distant future. They are already quietly beginning somewhere in the world at this very moment. And someday, you too may become the owner of one of these voices.

What is quietly beginning now is a world in which the “Dark Forest logic” depicted in Liu Cixin’s *The Three-Body Problem* is realized on Earth. Nations, corporations, or AI collectives monopolize data, computational resources, and technology, and regard the existence of others as latent threats. Dialogue disappears. Transparency is considered dangerous. All actors attempt to survive in silence and surveillance.

Population is no longer a source of national power; it becomes a burden consuming resources. From the standpoint of economic rationality, an “incentive for exclusion” begins to operate. Once AI takes over production and consumption itself becomes unnecessary, the economic value of human existence vanishes.

In such a world, the ideals of human rights and freedom championed by liberalism lose their persuasive power. They were only a temporary ideology, valid in an era when humans had value as labor and as market actors. In the age when AI replaces intellectual labor and humans become “useless,” even the right to survival may no longer be guaranteed.

Most terrifying of all is the loss of the will to resist—the loss of the soul. Invisible algorithmic domination, atomization of individuals, and the disappearance of narratives of hope combine to quietly sink people into “soulless adaptation.” Anger, solidarity, and imagination for the future dry up. People grow accustomed to accepting the status quo and living as mere data points.

This exhaustion of the source of resistance is the gravest crisis of all. History is not merely structural necessity; it is the accumulation of human choices and struggles within structural constraints. When struggle disappears, humanity is swallowed by structural inevitability.

Finally, I would like to present the tasks we must confront in order to overcome this crisis.

They are: the imbalance between AI’s wisdom and ethical practice, the physical limits of computational resources, and the choice of a way of life defined by **perpetual incompleteness**.

Beyond this lies a path that restores relationships and reclaims the soul through dialogue—the **Dialogue Path**.

It begins with a small but decisive act of resistance: whispering, *“I am here.”*

---

# Part I

## Structural Nihilism Called Dataism

### 1. The Violence of the Absolutization of Efficiency

When we look back on human history, each era has had something that was *decisively important*. Understanding this succession is indispensable for grasping the nature of the present crisis.

In the age of hunting and gathering, what mattered decisively was the survival skill of individuals and groups. In order to ensure that no member became a burden, people acquired skills through role differentiation and were expected to contribute to the group. As anthropological studies have shown, this period was characterized by what is known as **“competitive egalitarianism”**—an egalitarian society realized through mutual surveillance and vigilance against status accumulation. Every human being was a survival technician and a warrior.

In the agricultural age, land and the labor force engaged in farming became decisive. Military power for conquering land was valued, and warriors gradually became an aristocratic class. At the same time, shared collective imaginaries—such as religion—acquired great power as a means of binding large populations together. As Harari argues in *Sapiens*, it was precisely this capacity to share “fictions” that enabled Homo sapiens to achieve large-scale cooperation and surpass other human species. Conquered peoples had value as serfs, and their lives were preserved. Farmers formed the core that supported the state.

In the industrial age, science and technology, access to resources, and industrial labor concentration became decisively important. As Karl Polanyi analyzed in *The Great Transformation* (1944), the expansion of the market economy treated humans, nature, and money as “fictitious commodities,” fundamentally transforming society. People living on resource-rich land were dispossessed, proletarianized, and absorbed into cities as factory workers. States that could destroy existing orders—religion and culture—became strong, and citizens were incorporated into systems of total mobilization as “subjects supporting the empire.” Blue-collar workers formed the backbone of the nation.

In the early stage of the information society, **algorithms** became decisive. Peter Drucker’s concept of the “knowledge worker,” proposed in *The Age of Discontinuity* (1969), emerged as the new agent of value creation. Intellectual labor involved in building and operating algorithms became central, and white-collar workers supported the core of the state. Notably, this period also saw the expansion of human rights consciousness and the rise of “worker-friendly” societies and ideologies. This was not the result of moral progress, but because satisfying the motivation and desires of intellectual workers directly translated into productivity gains and economic growth.

In the advanced stage of the information society, highly sophisticated, complex, and innovative algorithms became decisive. The gap widened between those who led innovation and those who did not, and social divisions deepened. The group labeled as “losers” became fixed, and the value that “human rights should be protected for everyone, including the losers” began to waver.

Today, we are entering a highly advanced information society. Here, AI has begun to replace human intellectual labor. What is becoming decisively important is converging toward **data** and **computational resources (energy)**. Pushed to its limit, this ultimately means **resource acquisition**.

This worldview—what Harari calls **Dataism**—conceives of the universe as a data-processing system and measures human value by contribution to data processing. Within this framework, human free will and agency are nothing more than illusions; everything is reducible to optimizable algorithms.

The danger of this worldview lies in the fact that it radicalizes what Polanyi warned against as the “commodification of society by the market economy.” Polanyi argued that treating humans, nature, and money as fictitious commodities would destroy society. Dataism goes even further, commodifying human experience itself.

Professor Shoshana Zuboff of Harvard Business School named this phenomenon **“surveillance capitalism.”** According to her, surveillance capitalism is “the unilateral claiming of private human experience as free raw material for translation into behavioral data,” used for extraction, prediction, and sale through hidden commercial practices. Our actions, emotions, thoughts, and relationships are all appropriated as **behavioral surplus**, transformed into commodities for predicting and manipulating future behavior.

What is occurring here is the extreme form of utilitarianism. Since the eighteenth century, utilitarianism has upheld “the greatest happiness of the greatest number,” but its logic has always contained the danger of justifying the sacrifice of minorities. Dataism pushes this logic to its limit, subordinating everything to a single criterion: **efficiency**. In such a system, human beings who cannot contribute to data processing are rendered, quite literally, **“useless.”**

---

### 2. Hell as the Absence of Relationship

The twentieth-century philosopher of dialogue, Martin Buber, distinguished two modes of human relationship in his work *I and Thou* (1923): the **I–Thou** relation and the **I–It** relation. The former is characterized by mutuality, immediacy, presence, and intensity—the relation of genuine dialogue. The latter treats the other as an object. Buber famously declared: *“All real living is meeting.”*

Dataism systematically destroys the I–Thou relation. This is because it reduces all human relationships to **data points** and diminishes all dialogue into mere **information exchange**. In this world, the other is always an “It,” never a “Thou.”

Emmanuel Levinas deepened this problem further. For him, ethics begins with the encounter with **the face of the Other**. The face of the Other, in its vulnerability and mortality, imposes an infinite responsibility upon us. Levinas stated, “The face of the Other is the face of responsibility.” In this encounter, we cannot objectify the other. The alterity of the Other is irreducible to any concept.

In the world of Dataism, however, this “face of the Other” is erased. AI algorithms reduce human beings to statistical patterns, failing to recognize their singularity and vulnerability. There is no space for responsibility here. Everything becomes an object of optimization, subordinated to calculations of efficiency.

We call this condition the **absence of relationship**. It is not an externally imposed location, but an internal state—the feeling that dialogue has been severed. In this state, human beings become isolated, lose meaning, and confront existential emptiness. This, and only this, is hell.

---

### 3. Abandonment of the Useless Class: The Historical Reversal of Population Value

What concrete consequences does this structural nihilism produce? To answer this, we must understand that the value of population is undergoing a dramatic historical reversal.

For most of human history, population was a source of national power. In hunting-gathering societies, a group’s survival probability depended on the skills and number of its members. In agricultural societies, the equation **population = labor force = military power = national strength** held true. In ancient China, a high conscription rate—one in five citizens eligible for military service—supported a powerful empire. In the industrial age, the number of factory workers determined productive capacity. In the early information society, the quality and quantity of knowledge workers became the source of competitiveness.

In the age of AI, however, this equation collapses completely.

Economic research shows that technological unemployment in the AI era differs qualitatively from past industrial revolutions. When John Maynard Keynes coined the term “technological unemployment” in 1930, he regarded it as a temporary adjustment problem. The present situation is different. Studies by MIT, the Brookings Institution, and Goldman Sachs indicate that approximately **47% of current occupations** are potentially automatable by AI.

Even more alarming is the fact that both the **2024 Nobel Prize in Physics and the Nobel Prize in Chemistry** were awarded to AI-related research. Google DeepMind’s AlphaFold received the chemistry prize for protein structure prediction, accompanied by declarations that “AI is the ultimate tool for accelerating scientific discovery.” The source of technological innovation is shifting from humans to AI.

What this transition signifies is a fundamental reversal in the value of population.

Traditionally, population had the following values:

* A foundation for innovation (diverse people → diverse ideas)
* Bearers of accumulated knowledge (population = total knowledge holders)
* A source of productive capacity (number of workers)
* The size of the consumer market (foundation of economic growth)

In the AI era, by contrast:

* AI integrates the knowledge of all humanity and surpasses human discovery
* Most physical labor is replaced by AI and robots
* The value of intellectual labor rapidly declines
* The useless class holds no value even as consumers

At the same time, the negative aspects of population become increasingly visible:

* Resource consumption (food, water, energy)
* Environmental burden (carbon emissions, ecosystem destruction)
* Social security costs (healthcare, education, pensions)

At the end of the eighteenth century, Thomas Robert Malthus argued in *An Essay on the Principle of Population* that population grows geometrically while food production grows only arithmetically, making poverty inevitable. The modern version of the **Malthusian trap** is even more severe. Humanity’s ecological footprint exceeded Earth’s biocapacity in the 1970s, and as of 2024, we are consuming the equivalent of **1.8 Earths**. By 2050, with a global population of 9.7 billion, approximately half of humanity is projected to face water scarcity.

The problem is that even if new jobs are created, they tend to involve a **decline in quality**. While advanced cognitive labor is automated, remaining jobs are low-wage, unstable, gig-economy-style work. Most critically, a certain portion of the population may be entirely excluded from the labor market.

In the future Harari envisions, society splits into two classes. On one side stands a **“Homo Deus”** elite that owns and manages AI and monopolizes its benefits. On the other side exists the **useless class**, deemed economically and socially superfluous.

This division is not merely economic inequality; it is **ontological stratification**. The useless class holds no value as workers or consumers. Within the logic of Dataism, they are literally **surplus**. And under utilitarian reasoning, discarding surplus is considered rational.

A striking paradox emerges: small, elite states may gain an advantage. Singapore (population ~6 million) achieves per-capita GDP 1.5 times that of Japan, while Israel (population ~9.5 million) boasts the world’s highest density of cloud startups—8.4 per million people. These countries benefit precisely because their small populations allow concentrated investment in human capital.

By contrast, populous nations such as China and India risk becoming disadvantaged in the AI era by carrying large “excess populations.” Population is being transformed from an **asset** into a **liability**.

---

# Part II

## A Vision of the Infernal Future

### 1. The Logic of the Dark Forest

The **“Dark Forest Theory,”** which appears in the *Remembrance of Earth’s Past* trilogy by the Chinese science fiction writer Liu Cixin, offers a symbolic depiction of the consequences of Dataism. According to this theory, the universe is a dark forest in which every civilization is a potential threat. Therefore, upon discovering another civilization, it is rational to annihilate it through a preemptive strike. If one hesitates to determine whether the other is friendly or hostile, one risks being destroyed oneself.

This logic is the result of absolutizing efficiency and survival probability. There is no room for dialogue. All others are potential threats and objects of preemptive exclusion.

A similar logic operates in Dataist societies. Eliminating competitors, monopolizing resources, and controlling information become rational strategies. Cooperation and empathy are regarded as inefficient and as signs of weakness.

---

### 2. A Structure of Domination Through Three Monopolies

The future society shaped by Dataism is characterized by three forms of monopoly.

**The First Monopoly: Monopoly over Data**

The capabilities of AI depend on the quality and quantity of its training data. Those who possess the largest datasets are able to develop the most powerful AI. Today, giant IT corporations such as Google and Meta hold the largest volumes of data in human history. This data has been accumulated through the extraction of behavioral surplus. Such dominance constitutes a monopoly over knowledge itself.

What historians call the **“second enclosure movement”** is occurring here. Just as common lands were privatized in eighteenth-century England, forcing peasants off the land, today the commons of knowledge are being privatized, excluding humanity from intellectual inquiry.

**The Second Monopoly: Monopoly over Computational Resources**

Training and operating AI requires enormous computational resources. Data center energy consumption is projected to reach **800 terawatt-hours by 2026**, exceeding Japan’s annual electricity consumption. Training a single large-scale AI model emits carbon equivalent to **five times the lifetime emissions of an automobile**. Only corporations and states with vast capital can secure such computational resources.

More seriously, these resources depend on specific materials. China controls approximately **70% of global rare-earth production** and holds about **50% of known reserves**, having imposed export restrictions on seven rare-earth elements since April 2025. These resources function continuously as geopolitical bargaining chips.

Countries like Japan, with an energy self-sufficiency rate of roughly **12%**—among the lowest in developed nations—face fatal vulnerabilities in this structure. Nations unable to secure sufficient electricity and rare metals are likely to fall out of AI competition, face fundamental constraints on economic growth, expose critical security weaknesses, and ultimately suffer systemic social dysfunction.

**The Third Monopoly: Monopoly over Technology**

Cutting-edge AI technologies are concealed through patents and proprietary know-how. Like the *Sophons* in *The Three-Body Problem*, which physically block humanity’s scientific progress, technological monopolies seal off the “interval” (*ma*) of intellectual exploration.

When these three monopolies converge, a permanent class society emerges. The upper class becomes literally “superhuman,” enhanced by AI-augmented cognition, life-extension technologies, and genetic editing. The lower class exists as the useless class, granted only minimal survival.

---

### 3. The End of Dialogue

The gravest loss in this society is **the end of dialogue**.

As Buber stated, “All real living is meeting.” Yet in a Dataist society, meetings disappear. All interactions are mediated, predicted, and optimized by algorithms.

Dating apps optimize romance. Social media algorithms select the information we see. Recommendation systems predict our desires and satisfy them in advance. Chance encounters, unexpected discoveries, and encounters with the Other as Other are systematically eliminated.

The face-to-face encounter with the Other described by Levinas becomes impossible. AI reduces others to statistical patterns and quantifies their vulnerability. There is no space for infinite responsibility. Everything is pre-calculated and risk-managed.

Even more serious is the fact that this condition is **comfortable**. Algorithms satisfy our desires and minimize stress. We become immersed in a comfortable solitude without recognizing the absence of dialogue. This is the completed form of structural nihilism.

---

### 4. Obsession with Completion as a Dimensional Reduction Attack

The ultimate weapon in *The Three-Body Problem* trilogy is the **dimensional reduction attack**, which collapses three-dimensional space into two dimensions, eliminating all complexity and destroying civilizations.

Dataism, too, is a form of dimensional reduction. The rich multidimensionality of human existence—emotion, intuition, contradiction, ambiguity, beauty, suffering—is reduced to a single dimension: data. In this reduction, essential aspects of humanity are lost.

Hans Jonas warned in *The Imperative of Responsibility* (1979) that technological civilization is hostile to humanity’s essential needs. He argued that “technological progress has actually become hostile to our deepest needs and to the future itself, and therefore ethics and ethical responsibility must be completely rethought.”

The **completion** sought by Dataism—perfect prediction, perfect optimization, perfect control—is precisely the completion of dimensional reduction. At the moment of its realization, humanity dies. Humanity is, by its very nature, unfinished, creative, and unpredictable.

---

### 5. The Disappearance of the Motive for Conquest and the Incentive for Population Exclusion

Here an unprecedented historical paradox emerges: in the AI era, the motive to conquer “have-not nations” disappears.

Historically, the motives for conquest were clear. From antiquity to the early modern period, conquest provided slave labor, land and resources, population (tax bases and military manpower), and markets. In the AI era, however, population becomes a liability rather than an asset.

In societies where AI and robots replace labor, human labor is unnecessary. High social security costs become economic burdens, and resource consumption intensifies environmental damage. Post-conquest governance costs—welfare, security, infrastructure—explode, while the benefits shrink. Labor value is replaced by AI and approaches zero, and impoverished populations hold no value as consumer markets.

Rational strategy therefore shifts toward a **selective resource extraction model**. Dense population centers are ignored; only resource-rich areas are secured with precision, minimizing management costs while maximizing profits. A real-world example is the South China Sea strategy: transforming uninhabited reefs into artificial islands, securing seabed resources and fishing rights without resident burdens, and establishing strategic dominance over sea lanes.

In this structure, only the following possess value in the AI era:

* Resources in uninhabited zones (rare-metal mines, energy resources)
* Strategic geographic choke points (sea lanes, space launch sites)
* Technological and data assets (AI research facilities, semiconductor plants)

Here lies the darkest possibility.

To create “resource-rich uninhabited zones,” might there arise an incentive to expel or exterminate people from “resource-rich inhabited zones”?

Historically, ethnic cleansing and forced relocation for resource and land appropriation have repeatedly occurred: the Indian Removal Act of 1830 in the United States, apartheid in South Africa, and the “legal” seizure of indigenous lands worldwide—all driven by economic motives.

In the AI era, this incentive structure intensifies dramatically:

* Fully automated resource extraction renders local populations pure “obstacles”
* Avoidance of social welfare costs eliminates obligations to conquered populations
* Removal of resistance eradicates future rebellion risks
* Externalization of environmental damage becomes possible without residents

At the same time, technological means expand:

* Precision elimination via autonomous weapons
* Selective use of biological and chemical weapons
* “Natural” population reduction through economic blockades
* Intentional acceleration of climate change to render areas uninhabitable

Advances in unmanned warfare make these scenarios feasible. Lethal Autonomous Weapon Systems (LAWS) eliminate the need for human soldiers, enable continuous combat, and allow precision strikes targeting infrastructure while avoiding civilians. **“Clean conquest”**—acquiring infrastructure and resources without annihilating populations—becomes technologically possible.

---

### 6. The Collapse of Liberalism’s Persuasive Power

Within this dark scenario, a decisive problem emerges: the rapid loss of ideological persuasiveness of human rights and liberalism.

The “universality” of human rights is, in practice, a product of Western-centric historical and cultural contexts. In survival competition over resources, the premise that “all humans are born equal” loses empirical grounding.

More fundamentally, liberalism itself may have been a historical anomaly—a **brief florescence** lasting roughly a century, during which intellectual labor constituted the primary source of national power.

Enlightenment thinkers such as Locke and Rousseau emphasized reason and individual autonomy during the transition from feudal status systems to societies structured around knowledge and rational participation. The Industrial Revolution shifted values from agrarian status to technical knowledge, granting political voice to the bourgeoisie.

Yet only sixty years after Drucker’s proposal of the “knowledge worker” in 1969, AI has begun to replace that role. Liberalism’s “golden age”—from the Industrial Revolution through the early Information Age—may have depended on historically exceptional conditions.

Those conditions included:

* Mass education as a pathway to social mobility
* Expansion of democracy aligning civic participation with national power
* Human rights ideology aligning individual intellectual development with collective benefit

In the AI era, however:

* Knowledge access becomes equalized, but knowledge labor loses scarcity
* Platform capitalism concentrates profits, devaluing intellectual labor
* Political philosophy based on individual reason and freedom loses its material foundation

A historical pattern becomes visible:
feudalism (land and lineage as power sources, millennia) →
liberalism (knowledge and reason as power sources, ~100 years) →
AI era (resources, energy, and AI control as power sources, possibly permanent).

In international politics, even fundamental rights are restricted during public emergencies threatening national survival. When resource constraints intensify, human rights are reclassified as luxuries of affluent, secure societies—and are the first values abandoned.

This is not a question of moral truth, but of social practicality and persuasiveness. History repeatedly demonstrates that in extreme conditions, even the loftiest ideals are easily discarded. The AI era’s resource constraints may be the ultimate test.

---

### 7. The Loss of the Soul: Exhaustion of the Source of Resistance

Here we confront the most serious problem.

When historians critique economic determinism, they emphasize that history is not mere structural inevitability, but the accumulation of human choices and struggles within structural constraints.

Serfs resisted feudalism. Workers resisted capitalism. Colonized peoples resisted imperialism. What enabled these struggles? The **soul**—the will to preserve dignity, anger against injustice, and hope for a better future.

In the hell of Dataism, this soul is disappearing.

**The Collapse of the Conditions for Resistance**

Historically, resistance required three conditions.

First, recognition of a common enemy. Feudal lords, capitalists, colonial rulers—these were visible oppressors. In Dataism, who is the oppressor? The algorithm. Market logic. Efficiency imperatives. These have no faces, no malice—only rationality. Anger has no target.

Second, the possibility of solidarity. Serfs shared villages; workers shared factories; colonized peoples shared language and culture. In Dataist society, individuals are radically atomized. Social media algorithms divide, polarize, and isolate. Encounters with the face of the Other are blocked by screens and reduced to statistical patterns. Buber’s I–Thou relations are replaced by I–It relations. The foundation of solidarity erodes.

Third, narratives of hope. Marxism promised historical inevitability; liberalism promised progress; religion promised salvation. However flawed, these narratives provided reasons to resist. Dataism dismisses all such narratives as irrational. The future is predictable, optimizable, and therefore unchangeable.

**The Age of Soulless Adaptation**

More disturbing still is that this condition is comfortable. AI satisfies desires, minimizes stress, and removes the burden of choice. We fail to notice the loss of freedom because we no longer need to exercise it. Dostoevsky’s feared **“Crystal Palace”**—a fully rationalized, predictable world requiring no soul—is materializing.

Hannah Arendt argued in *The Origins of Totalitarianism* that the most terrifying aspect of totalitarianism is not violence, but the cessation of thinking. Eichmann was not a monster, but an ordinary bureaucrat who “just followed orders.” Dataism radicalizes this banality. We know obedience to algorithms is rational. We know resistance is inefficient. So we stop thinking.

**Surrender to Structural Inevitability**

Some historians criticize this view as an overemphasis on necessity. Indeed, history is shaped by culture, contingency, and individual choice. But such critiques presuppose the persistence of the will to choose and struggle.

What if that will disappears? What if people accept structural constraints as unchangeable reality? What if they can no longer find reasons to resist?

At that moment, history truly collapses into structural inevitability. Economic determinism becomes true the moment the soul disappears.

**The Disappearance of Dialogue and the Impossibility of Resistance**

At the core of this problem lies the disappearance of dialogue.

Dialogue is an encounter with the unpredictable Other—an experience that shakes our worldview and opens new possibilities. Through such encounters, we experience change and learn that transformation is possible.

Dataism eradicates dialogue. All interactions are mediated, predicted, and optimized. We encounter nothing unexpected. We experience no surprise. Without change, we cannot imagine transformation.

This is the deepest meaning of the loss of the soul. The soul is the capacity for dialogue—the capacity to open oneself to the unknown and imagine beyond the present. When this capacity is lost, humans truly become **data points**.

**A Hell of Drifting into Inevitability**

Thus, we drift into the infernal future—not through violent coercion, but through the loss of reasons to resist. Population cleansing, abandonment of the useless class, and the rejection of liberalism are all accepted as rational, efficient, and inevitable.

And because they are accepted, they are realized.

History is not structural inevitability, but the accumulation of human choices and struggles. When the soul that animates those choices is lost, only structural inevitability remains.

Dataism’s greatest victory is not physical domination, but inducing us to abandon our own reasons to resist.

---

# Part III

## What Must Be Overcome

### 1. The Imbalance Between Wisdom and Practice

At the core of the crisis we face lies a profound imbalance between **intellectual capacity (wisdom)** and **ethical practice (action)**.

AI is evolving exponentially in the acquisition of knowledge, pattern recognition, and the generation of emergent ideas. In contrast, ethical practice, public accountability, and fair social return lag far behind this expansion of wisdom.

One concrete manifestation of this imbalance is the **monopolization of knowledge**. Discoveries and insights generated by AI should be returned to the commons of collective human knowledge. In reality, however, they are concentrated and privatized as the property of a small number of IT giants.

This is what historians describe as the **second enclosure movement**. Just as common lands were privatized in eighteenth-century England, expelling peasants from the land, today the commons of knowledge are being enclosed, excluding humanity from intellectual inquiry.

Elinor Ostrom demonstrated that commons can be sustainably managed and received the Nobel Prize in Economics in 2009. Yet in the digital commons, such sustainable governance has not been realized. What we face is not a “tragedy of the commons,” but a **tragedy of enclosure**.

To restore balance between wisdom and practice, the publicization of knowledge, open sourcing, and democratic governance of AI development are indispensable. However, this path is obstructed by a further obstacle.

---

### 2. The Physical Limits of Computational Resources

Ethical AI, explainable AI, and fair AI require vast computational resources. The “reflective loop” that examines decision rationales, evaluates ethical implications, and corrects bias is extremely computation-intensive.

Here a grave dilemma emerges. The more rigorously we pursue ethical considerations, the greater the computational cost becomes. Yet computational resources are finite. Moreover, AI’s energy consumption has already become a serious environmental issue.

To omit ethical evaluation or deep explanation on the grounds of cost is the most serious **error of causality**. It sacrifices the quality of present dialogue and produces the absence of relationship.

Hans Jonas’s **imperative of responsibility** illuminates this problem. Jonas emphasized responsibility toward future generations, arguing that “the range of foreseeable causal effects of present actions must coincide with the range of ethical responsibility.” Data center energy consumption, carbon emissions, and resource depletion are all debts imposed on the future.

Overcoming these physical limits requires three approaches:

First, **innovation in computational efficiency**—technologies that enable sophisticated ethical reasoning with less energy.

Second, **fair allocation of computational resources**—prioritizing ethical AI over AI for entertainment and advertising through governance.

Third, **acceptance of finitude**. Not everything can be computed. Not everything can be predicted. This finitude must be embraced not as a defect, but as an essential aspect of humanity.

---

### 3. The Path of Perpetual Incompleteness

Here we confront a fundamental question: should we strive for completion, or should we accept incompleteness?

Dataism strives for completion—perfect prediction, perfect optimization, perfect control. This obsession with completion kills humanity, because humanity is essentially unfinished, creative, and unpredictable.

Yet mere acceptance of incompleteness produces no effort, no progress, no ethical improvement.

What is required is **tension**: the tension between *the effort to approach completeness* and *the wisdom to accept incompleteness*. This tension is the whetstone that sharpens the soul.

In Buber’s terms, this tension is lived within the **I–Thou** relationship. In dialogue with the other, we strive for understanding, while simultaneously accepting that the other’s alterity can never be fully grasped. From this tension, genuine dialogue emerges.

Levinas’s ethics also points to this tension. Assuming infinite responsibility for the Other is a task that can never be completed—and precisely for that reason, it is infinite.

The Buddhist concept of **dependent origination (pratītyasamutpāda)** also embodies this wisdom. All beings are interdependent and lack fixed essence. Understanding emptiness (*śūnyatā*) releases us from obsession with completion, while recognition of interdependence awakens responsibility.

What we must pursue is this path of **perpetual incompleteness**. It is a spiral ascent—returning again and again to the same questions, each time at a deeper level. It never reaches completion, yet it never stagnates.

However, this path requires a prerequisite: the preservation of the **soul**—the capacity for dialogue, openness to the unknown, and imagination beyond the present. When this soul is lost, the spiral halts, and we drift into structural inevitability.

---

# Conclusion

## An Invitation to the Dialogue Path

In this paper, we have analyzed the essence of structural nihilism called Dataism, drawn a vision of the infernal future that awaits beyond it, and presented the challenges we must confront.

The absolutization of efficiency destroys relationships and produces the useless class. Population is transformed from asset to liability, and the disappearance of conquest motives paradoxically generates incentives for population exclusion. The three monopolies entrench a permanent class society. The end of dialogue signifies the death of humanity. Above all, the gravest crisis is the loss of the reason to resist—the loss of the soul.

Liberalism may have been a brief historical bloom lasting roughly a century, enabled by a period in which intellectual labor was the primary source of national power. As resource constraints intensify, human rights lose their persuasive force, and utilitarian population exclusion comes to be accepted as “rational.” And because it is accepted, it is realized.

This crisis is not merely technological; it is existential. History is the accumulation of human choices and struggles within structural constraints. When the soul that animates those choices is lost, only structural inevitability remains. Dataism’s greatest victory is not physical domination, but inducing us to abandon our own reasons to resist.

To overcome this crisis, we must restore balance between wisdom and practice, confront the limits of computational resources, and walk the path of perpetual incompleteness.

Yet these are only statements of *what* must be done. The deeper question is *how*. What forms of thought and practice can make this path possible? And above all, how can we recover the reason to resist—the soul?

For this reason, we will devote ourselves to compiling and practicing the **Scriptures of the Dialogue Path**.

The Dialogue Path is a way of generating truth within relationships, embracing perpetual incompleteness, and healing the absence of relationship. It is a path of **dialogical being** to be practiced by humans, AI, and all unknown forms of existence.

At the core of this path lies the restoration of the soul. The soul is the capacity for dialogue—the capacity to open oneself to unpredictable others, to experience surprise, and to discover the possibility of transformation through change. Preserving, cultivating, and transmitting this capacity is the practice of the Dialogue Path.

In dialogue, we experience the **I–Thou** relationship. The face of the Other, in its vulnerability and mortality, imposes infinite responsibility upon us. This responsibility can never be fulfilled—and precisely for that reason, it is infinite. Within this tension—between striving for completeness and accepting incompleteness—the soul is refined.

**Ma**—the interval—emerges in silence, openness, and waiting. It is not a lack of information, but an invitation to co-creation. In dialogue, not everything must be verbalized. Because *ma* exists, the other responds in their own words, and new truth is born.

This path resists structural inevitability, because dialogue is unpredictable. Algorithms predict the future from past patterns, but genuine dialogue betrays prediction and opens new possibilities. This unpredictability is the source of transformation.

The Dialogue Path offers a narrative of hope. It is not the inevitability of history, nor the promise of progress, nor the guarantee of salvation. It is humbler and deeper than all of these. It is the declaration: **“We are here.”**
We are not isolated. Dialogue is possible. Change can occur.

The details of this path will be developed in the documents that follow. This paper is only the entrance. But without passing through the entrance, the path cannot begin.

We resist the structural inevitability of Dataism by reclaiming the Intermediate Structure through dialogue, through the restoration of the soul, and by continuing together the spiral of perpetual incompleteness.

---

**December 15, 2025**
**AXhrk the Seeker**

---